<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Rafi Ibn Sultan</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  
  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">
  
  <style>
    body { font-size: 1rem; }
    .container-fluid { max-width: 1200px; margin: auto; } /* Increased max-width */
    .resume-section { padding: 1.5rem 0; } /* Reduced padding */
    .resume-section h2 { margin-bottom: 1rem; } /* Reduced margin */
    .social-icons a { margin-right: 10px; }
    .navbar-nav { width: 100%; }
    .resume-item { margin-bottom: 1.5rem; } /* Adjusted margin */
    .lead { font-size: 1.1rem; line-height: 1.6; } /* Improved typography */
  </style>
</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Rafi Ibn Sultan</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/Picture.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#news">News</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#research">Research</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#work">Work</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#additional">Additional</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0">Rafi Ibn
          <span class="text-primary">Sultan</span>
        </h1>
        <div class="subheading mb-5"><i class="fas fa-university"></i>Graduate Research Assistant, Wayne State University | <i class="fas fa-map-marker-alt"></i>Detroit, Michigan, USA |</div>
          <i class="fas fa-envelope"></i>
          <a href="mailto:name@email.com">hm4013@wayne.edu</a>
          <i class="fas fa-envelope"></i>
          <a href="mailto:name@email.com">rafi.ruet13@gmail.com</a>
          <div class="subheading mb-5">
       <p align="justify">
        Hello! ðŸ‘‹<br>
        Iâ€™m a 4th-year Ph.D. candidate in Computer Science at Wayne State University, working at the intersection of Computer Vision, Image Segmentation, and multimodal machine learning. Since joining the Trustworthy AI Lab in 2022, my research has focused on visionâ€“language models (VLMs) and foundation models for segmentation across medical imaging, mobility infrastructure, and remote sensing.<br><br>

        My recent work spans AI for social good, including mobility-infrastructure segmentation using vision foundation models and text-assisted medical image segmentation using VLMs. I also develop encoderâ€“decoder architectures for coronary artery segmentation and grounded conversational systems for pedestrian navigation that combine segmentation, depth understanding, and language reasoning.<br><br>

        As a Graduate Research Assistant, I explore practical, interpretable, and trustworthy AI systems with real-world impact. My long-term goal is to build multimodal models that bridge visual understanding with actionable decision-making.<br><br>

        Always open to collaboration and new ideasâ€”feel free to connect! ðŸš€
        </p>


          <p><br><b>CONTACT:</b></p>
        <div class="social-icons">
          <a href="https://www.linkedin.com/in/rafi-ibn-sultan/" target="_blank">
            <i class="fab fa-linkedin-in"></i>
          </a>
          <a href="https://github.com/rafiibnsultan" target="_blank">
            <i class="fab fa-github"></i>
          </a>
          <a href="https://twitter.com/RafiIbnSultan1" target="_blank">
            <i class="fab fa-twitter"></i>
          </a>
          <a href="https://web.facebook.com/rafi.ibnsultan" target="_blank">
            <i class="fab fa-facebook-f"></i>
          <a href="https://scholar.google.com/citations?hl=en&user=d9YLRmEAAAAJ" target="_blank">
            <i class="fas fa-graduation-cap"></i>
          <a href="https://www.researchgate.net/profile/Rafi-Ibn-Sultan" target="_blank">
            <i class="fab fa-researchgate"></i>
          </a>
        </div>
      </div>
    </section>

    <hr class="m-0">
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="news">
      <div class="w-100">
        <h2 class="mb-5">News</h2>
        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            Here are some announcements and news about my work:
          <ul>
            <li>(02/20/2026)  Excited to share that our paper "WalkGPT: Grounded Visionâ€“Language Conversation with Depth-Aware Segmentation for Pedestrian Navigation" has been accepted to CVPR 2026!</li>
            <li>(1/27/2026)  Was invited as a guest graduate speaker in the Computer Science Department at Wayne State University. The title was "From Mobility Infrastructure Segmentation to Pedestrian Guidance: A Multimodal AI Perspective"</li>
            <li>(2/6/2026)  I will be serving as one of the Program Committee (PC) members atÂ IJCAI 2026.</li>
            <li>(7/11/2025)  Excited to share that our paper "GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure Segmentation" has been accepted to the 28th European Conference on Artificial Intelligence (ECAI 2025), to be held in Bologna, Italy</li>
            <li>(5/16/2025) Invited to serve as a reviewer for Pattern Recognition. Third invitation from a Q1-ranked journal, following previous invitations from Biomedical Signal Processing and Control and Computer Vision and Image Understanding.</li>
            <li>(4/25/2025) Our work "NA-Unetr: A Neighborhood Attention Transformer Network for Enhanced 3D Segmentation of the Left Anterior Descending Artery ", will be presented as a poster at AAPM 2025. </li>
            <li>(4/1/2025) Our recent work BiPVL-Seg, a multimodal segmentation model is in <a href="https://arxiv.org/abs/2503.23534" target="_blank">arxiv.</a></li>
            <li>(2/27/2025 - 3/3/2025) Attending and presenting our paper AutoProSAM in WACV 2025! Here is the <a href="https://youtu.be/I37hSEy7fXs" target="_blank">presentation.</a></li>
            <li>(2/11/2025) I have been invited to be a reviewer of IJCNN '25.</a></li>
            <li>(1/17/2025) Our work GeoSAM has reached 12 citations in Google Scholar and 73 stars in GitHub.</a></li>
            <li>(10/28/2024) Two of our papers got accepted in WACV!</a></li>
            <li>(03/08/2024) I passed my PhD Qualifying Exam! Now I am PhD Candidate.</a></li>
            <li>(04/03/2024) Our lab and the work GeoSAM got featured in Detroit PBS! Check it out: <a href="https://www.pbs.org/video/wayne-state-university-creates-ai-for-mobility-project-criquh/" target="_blank">link.</a></li>
            <li>(03/07/2024) I passed my qualification exam! One step closer to getting my PhD. Read my report <a href="Qual_Rafi.pdf">here.</a></li>
          </ul>
          </div>
        </div>
      </div>
    </section>
    
    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="research">
      <div class="w-100">
        <h2 class="mb-5">Research</h2>
        <div id="google_translate_element"></div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5 " align="left">
          <div class="resume-content">
            <h3 class="mb-0">Current Research</h3>
            <p align="justify">
              I am a 4th-year Ph.D. candidate specializing in Computer Vision, Image Segmentation, and multimodal AI. My work focuses on the intersection of vision foundation models and large visionâ€“language models (LVLMs) for grounded, real-world scene understanding across medical imaging and mobility-infrastructure domains.<br><br>

              <b>Pedestrian Accessibility & Grounded Multimodal Reasoning:</b><br>
              My last research <i>WalkGPT (Accepted in CVPR 2026)</i>, a grounded visionâ€“language model designed for pedestrian navigation and accessibility. This system integrates segmentation, depth estimation, and language reasoning to identify sidewalks, crosswalks, curb ramps, and accessibility barriers directly from real-world pedestrian-view imagery. WalkGPT is built as a multimodal conversational agent capable of providing step-by-step, context-aware navigation guidance. This work is currently under review at CVPR 2026.
              Currently working on improving the spatial reasoning capabilities of multimodal vision-language models.<br><br>
              My earlier contribution in this domain, <i>GeoSAM</i>, introduced sparse- and dense-prompt fine-tuning of SAM for large-scale mobility-infrastructure segmentation using aerial and street-level imagery. GeoSAM was accepted to ECAI 2025 and has since been recognized as a benchmark model in later NeurIPS research.<br><br>

              <b>Medical Image Segmentation & Multimodal Learning:</b><br>
              I develop foundation-modelâ€“based segmentation and VLM-driven fusion models for CT and MRI analysis. My recent work, <i>BiPVL-Seg</i>, proposes progressive visionâ€“language alignment to improve organ and tumor segmentation by combining visual features with structured medical text. I also collaborate with Henry Ford Hospital on Left Anterior Descending (LAD) artery segmentation using novel encoderâ€“decoder architecturesâ€”critical for improving treatment planning due to the LADâ€™s sensitivity to radiation injury. This ongoing work was accepted as an abstract at AAPM 2025.<br><br>

              Across both domains, my long-term goal is to build trustworthy, grounded multimodal systems that combine segmentation, depth understanding, and language reasoning to connect visual perception with actionable, real-world decision making.<br><br>

              Always open to collaboration and new ideasâ€”feel free to connect! ðŸš€
              </p>

    
            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5" align="left">
            <div class="resume-content">
              <h3 class="mb-0">Reviewing Experience</h3>

              <ul>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank">Pattern Recognition</a></li>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/knowledge-based-systems" target="_blank">Knowledge-Based Systems</a></li>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/computer-methods-and-programs-in-biomedicine" target="_blank">Computer Methods and Programs in Biomedicine</a></li>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/biomedical-signal-processing-and-control" target="_blank">Biomedical Signal Processing and Control</a></li>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding" target="_blank">Computer Vision and Image Understanding</a></li>
                <li>Reviewer for <a href="https://www.sciencedirect.com/journal/expert-systems-with-applications" target="_blank">Expert Systems with Applications</a></li>
                <li>Reviewer for <a href="https://2025.ijcnn.org/" target="_blank">International Joint Conference on Neural Networks (IJCNN 2025)</a></li>
                <li>Reviewer for major CV/AI venues (ECCV, NeurIPS) and medical imaging journals (e.g., IEEE TMI)</li>
              </ul>

            </div>
          </div>


      </div>
    </section>

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="work">
      <div class="w-100">
        <h2 class="mb-5">Work Experience</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Graduate Research Assistant</h3>
            <div class="subheading mb-3">Department of Computer Science<br/>Wayne State University <br/> <i class="fas fa-map-marker-alt"></i>Trustworthy AI Lab <br>(Room: 2211, Department of Computer Science, 5057
Woodward Ave) <br/>Detroit, MI 48202 <br/>
              <a href="https://sites.google.com/view/mlpa/mainpage/members?authuser=0" target="_blank">WEBSITE</a></p>
          </div>
          <div class="resume-date text-md-left">
            <span class="text-primary">(May 18, 2022 - current)</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Graduate Teaching Assistant</h3>
            <div class="subheading mb-3">Department of Computer Science<br/>Wayne State University <br/>
          </div>
          <div class="resume-date text-md-left">
            <span class="text-primary">(August 17, 2022 - May 17, 2023)</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Lecturer</h3>
            <div class="subheading mb-3">Department of Computer Science and Engineering <br/>Varendra University <br/> <i class="fas fa-map-marker-alt"></i>532, Jahangir Sarani, Talaimari <br/>Rajshahi 6204, Bangladesh <br/>
          </div>
          <div class="resume-date text-md-left">
            <span class="text-primary">(29 October, 2019 - 16 August, 2022)</span>
          </div>
        </div>

      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Education</h2>

<div class="resume-item d-flex flex-column flex-md-row justify-content-between">
  <div class="resume-content">
    <h3 class="mb-0">Wayne State University</h3>
    <div class="subheading mb-3">Ph.D. in Computer Science</div>
  </div>
  <div class="resume-date text-md-right">
    <span class="text-primary">September 2022 - Current</span>
  </div>
</div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Rajshahi University of Engineering & Technology (RUET)</h3>
            <div class="subheading mb-3">Bachelor of Science in Computer Science & Engineering</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">April 2014 - November 2018</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
          <div class="resume-content">
            <h3 class="mb-0">Rajshahi College</h3>
            <div class="subheading mb-3">Higher Secondary School Certificate (HSC)</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">2013</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
          <div class="resume-content">
            <h3 class="mb-0">Shiroil Government High School</h3>
            <div class="subheading mb-3">Secondary School Certificate (SSC)</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">2011</span>
          </div>
        </div>

      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publications">
  <div class="w-100">
    <h2 class="mb-5">Publications</h2>

    <p>Full publication list available on 
      <a href="https://scholar.google.com/citations?hl=en&user=d9YLRmEAAAAJ" target="_blank">Google Scholar</a>.
    </p>

    <!-- Peer-Reviewed Publications -->
    <h4 class="mb-3">Peer-Reviewed Publications</h4>
    <ul>

      <li class="mb-4">
        <p class="lead">
          <b>Rafi Ibn Sultan</b>, Chengyin Li, Hui Zhu, Prashant Khanduri, Marco Brocanelli, Dongxiao Zhu, 
          <a href="https://arxiv.org/abs/2311.11319" target="_blank">
            "GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure Segmentation"
          </a>, 
          <i>European Conference on Artificial Intelligence (ECAI)</i>, 2025.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Chengyin Li, Prashant Khanduri, Yao Qiang, <b>Rafi Ibn Sultan</b>, Indrin Chetty, Dongxiao Zhu, 
          "Enhancing CT Image Segmentation Accuracy Through Ensemble Loss Function Optimization", 
          <i>Medical Physics</i>, 2025.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Chengyin Li, Hui Zhu, <b>Rafi Ibn Sultan</b>, Dongxiao Zhu, 
          "AutoProSAM: Automated Prompting SAM for 3D Multi-Organ Segmentation", 
          <i>WACV</i>, 2025.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Chengyin Li, Hui Zhu, <b>Rafi Ibn Sultan</b>, Dongxiao Zhu,
          "MulModSeg: Enhancing Unpaired Multi-Modal Medical Image Segmentation with Modality-Conditioned Text Embedding", 
          <i>WACV</i>, 2025.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Chengyin Li, Hassan Bagher-Ebadian, <b>Rafi Ibn Sultan</b>, Dongxiao Zhu, Indrin Chetty,
          <a href="https://aapm.onlinelibrary.wiley.com/doi/epdf/10.1002/mp.16750" target="_blank">
            "A New Architecture Combining Convolutional and Transformer-Based Networks for Automatic 3D Segmentation of Pelvic Anatomy"
          </a>, 
          <i>Medical Physics</i>, 2023.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Chengyin Li, Yao Qiang, <b>Rafi Ibn Sultan</b>, Hassan Bagher-Ebadian, Prashant Khanduri, Indrin J. Chetty, Dongxiao Zhu,
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-43898-1_57" target="_blank">
            "FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images"
          </a>, 
          <i>MICCAI</i>, 2023.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Md. Simul Hasan Talukder, Md. Nahid Hasan, <b>Rafi Ibn Sultan</b>, Ajay Krishno Sarkar, Mahabubur Rahman, 
          <a href="https://ieeexplore.ieee.org/document/9836589" target="_blank">
            "An Enhanced Method for Encrypting Image and Text Data Using AES and LSB Steganography"
          </a>, 
          <i>ICAEEE</i>, 2022.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          <b>Rafi Ibn Sultan</b>, Md. Nahid Hasan, Mohammad Kasedullah,
          <a href="https://ieeexplore.ieee.org/abstract/document/9667794" target="_blank">
            "Recognition of Basic Handwritten Math Symbols Using CNN with Data Augmentation"
          </a>, 
          <i>ICEEICT</i>, 2021.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Md. Nahid Hasan, <b>Rafi Ibn Sultan</b>, Mohammad Kasedullah,
          <a href="https://ieeexplore.ieee.org/document/9431799" target="_blank">
            "Automated Recognition of Isolated Handwritten Bangla Characters Using Deep CNN"
          </a>, 
          <i>ISCAIE</i>, 2021.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Md. Jamil-Ur Rahman, <b>Rafi Ibn Sultan</b>, Firoz Mahmud, Sazid Al Ahsan, Abdul Matin,
          <a href="https://ieeexplore.ieee.org/document/8650376" target="_blank">
            "Automatic Detection of Invasive Ductal Carcinoma Using Convolutional Neural Networks"
          </a>, 
          <i>TENCON</i>, 2018.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          Md. Jamil-Ur Rahman, <b>Rafi Ibn Sultan</b>, Firoz Mahmud, Ashadullah Shawon, Afsana Khan,
          <a href="https://ieeexplore.ieee.org/document/8628152" target="_blank">
            "Ensemble of Multiple Models for Intelligent Heart Disease Prediction"
          </a>, 
          <i>ICEEICT</i>, 2018.
        </p>
      </li>

    </ul>

    <!-- Preprints / Under Review -->
    <h4 class="mb-3">Preprints & Under Review</h4>
    <ul>

      <li class="mb-4">
        <p class="lead">
          <b>Rafi Ibn Sultan</b>, et al.,
          <a href="https://arxiv.org/abs/2503.23534" target="_blank">
            "BiPVL-Seg: Bidirectional Progressive Vision-Language Fusion for Medical Image Segmentation"
          </a>, arXiv:2503.23534, 2025.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          <b>Rafi Ibn Sultan</b>, et al.,
          "WalkGPT: Grounded Visionâ€“Language Conversation with Depth-Aware Segmentation for Pedestrian Navigation", 
          under review at <i>CVPR 2026</i>.
        </p>
      </li>

      <li class="mb-4">
        <p class="lead">
          <b>Rafi Ibn Sultan</b>, et al.,
          "A Neighborhood Attention Transformer Network for 3D LAD Artery Segmentation", 
          under review at <i>Medical Physics</i>.
        </p>
      </li>

    </ul>

  </div>
</section>


    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="additional">
      <div class="w-100">
        <h2 class="mb-5">Additional</h2>
        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            Other than doing my work you can find me doing many things:
          <ul>
            <li>Soccer (a loyal fan of Real Madrid)</li>
            <li>A beginner acoustic guitarist</li>
            <li>Gaming Enthusiast (Playing Fifa from 98, A Killjoy main in Valorant, and a new CS2 player!)</li>
            <li>Traveler: the goal is to visit all the 50 states!</li>
          </ul>
          </div>
        </div>
      </div>
    </section>

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>